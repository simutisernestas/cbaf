https://github.com/binli826/LSTM-Autoencoders
https://towardsdatascience.com/autoencoders-for-the-compression-of-stock-market-data-28e8c1a2da3e
https://github.com/tejaslodaya/timeseries-clustering-vae
https://github.com/jjakimoto/DQN
https://github.com/openai/baselines/tree/master/baselines/ppo2 

# DONE:
 * sample more sequences by random start indexes
 * reduce low-high & open-close columns into single by subtracting them
 * try removing kl-loss? - doesn't affect too much

# TODO:
 * model naming by parameters used
 * make validation dateset
 * explore coinbase database for more data
 * read more about kl-divergence loss
 * next step ???
 * binance has a lot more data, collect that
 * spark doesn't take numpy floats, conver all types of DF to python floats
   - https://stackoverflow.com/questions/38810390/cannot-create-dataframe-from-list-pyspark
 * reward must be approapriate to action taken
 * compare previous high to next low
 * research RL approaches
 * research that DQN link
 * add live data to RL step function along side the encoded vector
 * make the encoded vector much much smaller (20*6 < 512)
 * rework reward to be expressed as profit
 * episode ends when losses drop below a threshold ~5%

pip install tox
tox